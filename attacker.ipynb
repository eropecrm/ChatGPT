{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eropecrm/ChatGPT/blob/main/attacker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "https://colab.research.google.com/github/eropecrm/Adversarial-attack/blob/main/attacker.ipynb"
      ],
      "metadata": {
        "id": "T1s3MGCRvJLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import copy\n",
        "from abc import ABC, abstractmethod"
      ],
      "metadata": {
        "id": "nvgMRY-XvXqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y3V_lYzV-xV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f3f73a-5dca-4428-d539-bb1311e85713"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8etkcAOWOZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4b45cd-61f5-4068-99d8-4ace48aa189b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/AdversarialRobust-GAP-DSC\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/AdversarialRobust-GAP-DSC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDVbWp5FGlSm"
      },
      "source": [
        "### 출처:\n",
        "https://rain-bow.tistory.com/entry/%EC%A0%81%EB%8C%80%EC%A0%81-%EA%B3%B5%EA%B2%A9Adversarial-Attack-FGSMPGD\n",
        "\n",
        "https://github.com/Jeffkang-94/pytorch-adversarial-attack/blob/master/attack/Attacker.py\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fgsm_attack(image, epsilon, gradient): # gradient 의 요소별 부호 값을 얻어옵니다\n",
        "    # 기울기값의 원소의 sign 값을 구함, 입력 이미지의 각 픽셀에 sign_data_gradient를 적용해 작은 변화가 적용된 이미지를 생성.\n",
        "    sign_gradient = gradient.sign()\n",
        "    # 이미지 각 픽셀의 값을 sign_gradient 방향으로 epsilon 만큼 조절\n",
        "    perturbed_image = image + epsilon * sign_gradient\n",
        "    # [0,1] 범위를 벗어나는 값을 조절, 값 범위를 [0,1]로 유지하기 위해 자르기(clipping)를 추가\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    # 작은 변화가 적용된 이미지를 리턴\n",
        "    return perturbed_image"
      ],
      "metadata": {
        "id": "V6fm5cBc1Wtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDcaocGxGo91"
      },
      "outputs": [],
      "source": [
        "def pgd_attack(model, model_number, images, labels,loss,  device, batch_size, eps=0.1, alpha=2 / 255, attack_steps = 7):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    ori_images = images.data\n",
        "\n",
        "    for i in range(iters):\n",
        "\n",
        "        images.requires_grad = True\n",
        "\n",
        "        outputs = model.forward(images, batch_size).requires_grad_()\n",
        "        '''\n",
        "        for i in range (0,10):\n",
        "            model.set_zerograd(i)\n",
        "            '''\n",
        "        model.zero_grad()\n",
        "        cost = loss(outputs, labels).to(device)\n",
        "        cost.backward()\n",
        "\n",
        "        #gradient =model.get_sep_gredient(model_number=model_number,x=images,y_=labels,batch_size=batch_size)\n",
        "        adv_images = images + alpha * images.grad.data\n",
        "        eta = torch.clamp(adv_images - ori_images, min=-eps, max=eps)\n",
        "        images = torch.clamp(ori_images + eta, min=0, max=1).detach_()\n",
        "\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CW-L2 Attack\n",
        "# https://github.com/Harry24k/CW-pytorch/blob/master/CW.ipynb\n",
        "# Based on the paper, i.e. not exact same version of the code on https://github.com/carlini/nn_robust_attacks\n",
        "# (1) Binary search method for c, (2) Optimization on tanh space, (3) Choosing method best l2 adversaries is NOT IN THIS CODE.\n",
        "def cw_l2_attack(model, images, labels, targeted=False, c=1e-4, kappa=0, max_iter=1000, learning_rate=0.01) :\n",
        "\n",
        "    images = images.to(device)     \n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Define f-function\n",
        "    def f(x) :\n",
        "\n",
        "        outputs = model(x)\n",
        "        one_hot_labels = torch.eye(len(outputs[0]))[labels].to(device)\n",
        "\n",
        "        i, _ = torch.max((1-one_hot_labels)*outputs, dim=1)\n",
        "        j = torch.masked_select(outputs, one_hot_labels.byte())\n",
        "        \n",
        "        # If targeted, optimize for making the other class most likely \n",
        "        if targeted :\n",
        "            return torch.clamp(i-j, min=-kappa)\n",
        "        \n",
        "        # If untargeted, optimize for making the other class most likely \n",
        "        else :\n",
        "            return torch.clamp(j-i, min=-kappa)\n",
        "    \n",
        "    w = torch.zeros_like(images, requires_grad=True).to(device)\n",
        "\n",
        "    optimizer = optim.Adam([w], lr=learning_rate)\n",
        "\n",
        "    prev = 1e10\n",
        "    \n",
        "    for step in range(max_iter) :\n",
        "\n",
        "        a = 1/2*(nn.Tanh()(w) + 1)\n",
        "\n",
        "        loss1 = nn.MSELoss(reduction='sum')(a, images)\n",
        "        loss2 = torch.sum(c*f(a))\n",
        "\n",
        "        cost = loss1 + loss2\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Early Stop when loss does not converge.\n",
        "        if step % (max_iter//10) == 0 :\n",
        "            if cost > prev :\n",
        "                print('Attack Stopped due to CONVERGENCE....')\n",
        "                return a\n",
        "            prev = cost\n",
        "        \n",
        "        print('- Learning Progress : %2.2f %%        ' %((step+1)/max_iter*100), end='\\r')\n",
        "\n",
        "    attack_images = 1/2*(nn.Tanh()(w) + 1)\n",
        "\n",
        "    return attack_images"
      ],
      "metadata": {
        "id": "tRRhWz3poxoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDEHgvnhA_wC"
      },
      "source": [
        "### 4. Class 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PbzoW9gHHz9"
      },
      "outputs": [],
      "source": [
        "class Attacker:\n",
        "    def __init__(self, clip_max=0.5, clip_min=-0.5):\n",
        "        self.clip_max = clip_max\n",
        "        self.clip_min = clip_min\n",
        "\n",
        "    def generate(self, model, x, y):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jowmJNlzHWsX"
      },
      "outputs": [],
      "source": [
        "class BIM(Attacker):\n",
        "\n",
        "    def __init__(self, eps=0.15, eps_iter=0.01, n_iter=50, clip_max=0.5, clip_min=-0.5):\n",
        "        super(BIM, self).__init__(clip_max, clip_min)\n",
        "        self.eps = eps\n",
        "        self.eps_iter = eps_iter\n",
        "        self.n_iter = n_iter\n",
        "\n",
        "    def generate(self,model, device, lossf, batchsize,  x, y):\n",
        "        model.eval()\n",
        "        nx = x\n",
        "        ny = y\n",
        "        #nx = torch.unsqueeze(x, 0)\n",
        "        #ny = torch.unsqueeze(y, 0)\n",
        "        nx.requires_grad_()\n",
        "        eta = torch.zeros(nx.shape).to(device)\n",
        "\n",
        "        for i in range(self.n_iter):\n",
        "            out = model.forward(nx + eta, batchsize)\n",
        "            loss = lossf(out, ny)\n",
        "            #loss = F.cross_entropy(out, ny)\n",
        "            loss.backward()\n",
        "\n",
        "            eta += self.eps_iter * torch.sign(nx.grad.data)\n",
        "            eta.clamp_(-self.eps, self.eps)\n",
        "            nx.grad.data.zero_()\n",
        "\n",
        "        x_adv = nx + eta\n",
        "        x_adv.clamp_(self.clip_min, self.clip_max)\n",
        "        x_adv.squeeze_(0)\n",
        "\n",
        "        return x_adv.detach()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GAP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GAP, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.mean(x.view(x.size(0), x.size(1), -1), dim=2)"
      ],
      "metadata": {
        "id": "Va6wDKUsSs0l"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORkRUljh+ExsSCchhtUt6L",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}